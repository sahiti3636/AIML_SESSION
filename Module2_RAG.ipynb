{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgecVXWKdnuK44ecqG1acN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahiti3636/AIML_SESSION/blob/main/Module2_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-Augmented Generation (RAG) — Simple Demo\n",
        "\n",
        "In this notebook, we build a simple RAG system:\n",
        "1. Store documents\n",
        "2. Convert text into embeddings\n",
        "3. Retrieve relevant context\n",
        "4. Generate an answer using an LLM (Gemini)"
      ],
      "metadata": {
        "id": "yoEbjOgZemAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "dBBJH4_nfH0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycesF7V5eWq9"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-google-genai langchain_community langchain_core chromadb sentence-transformers pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "lGX0QW45fidA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "d1aZmOO5fQjC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"PASTE_YOUR_API_KEY_HERE\""
      ],
      "metadata": {
        "id": "MpG_r_orgAZL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our Knowledge Base"
      ],
      "metadata": {
        "id": "q77ONx1YhmIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload PDF"
      ],
      "metadata": {
        "id": "hXPM7GfNqqnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "NqFumX8fhhDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load PDF as Documents"
      ],
      "metadata": {
        "id": "NcJcOW5Cqyn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "all_documents = []\n",
        "\n",
        "for pdf_path in uploaded.keys():\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "    all_documents.extend(docs)"
      ],
      "metadata": {
        "id": "Z3HCs83Gq2V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Chunks"
      ],
      "metadata": {
        "id": "TANBsqZoq7Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(all_documents)"
      ],
      "metadata": {
        "id": "5dyMs4JJq-ew"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Embeddings + Store in Schema"
      ],
      "metadata": {
        "id": "QCUXreY6hryq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")"
      ],
      "metadata": {
        "id": "RRDMiKEThvoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "PgmNieUahynS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever (Semantic Search)"
      ],
      "metadata": {
        "id": "jFejsm4ell2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "y8-AFnfTh2Fr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main difference between active and passive electronic components?\"\n",
        "\n",
        "retrieved_docs = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "hh94niq-pnVM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs"
      ],
      "metadata": {
        "id": "Sx-rSmGwl2Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(retrieved_docs)"
      ],
      "metadata": {
        "id": "jLT3rEQ-0lZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini LLM"
      ],
      "metadata": {
        "id": "BpC-Tq9bl-Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "55LhBtYRl60Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final RAG Answer"
      ],
      "metadata": {
        "id": "wL2EdW_amLBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are an assistant that answers questions using the given context.\n",
        "\n",
        "Rules:\n",
        "- Use ONLY the information in the context.\n",
        "- Do NOT use outside knowledge.\n",
        "- If the context is insufficient, ask the user to rephrase the question\n",
        "  or provide more information.\n",
        "\n",
        "Answer Guidelines:\n",
        "- Write a clear and complete explanation.\n",
        "- Use 3–5 sentences.\n",
        "- Prefer simple language suitable for a beginner.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C5RgWM0imI7X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qepDiGixmPFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explain the 'Software as a Service' (SaaS) model in simple terms based on the document"
      ],
      "metadata": {
        "id": "P1_TYkut2_Ng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}