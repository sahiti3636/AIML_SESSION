# Hands-On AI/ML Session

This session introduces students to **how modern AI systems are built and used in practice**, with a strong focus on **Large Language Models (LLMs)** and hands-on experimentation.

The goal is not to train models from scratch, but to understand **how AI behavior is controlled through prompts, context, and decoding parameters**, just like in real-world applications.

---

## Session Structure

### 1. Big Picture: AI Today
- What AI systems look like today
- Where LLMs fit in the AI/ML landscape
- Real-world applications and use cases

---

### 2. Module 0: ML in a Nutshell & LLM Foundations
- Machine Learning vs Deep Learning vs LLMs
- Next-token prediction intuition
- Tokens and why they matter

---

### 3. Module 1: Using LLMs in Practice
- How text is converted to tokens and processed
- Self-attention and context understanding
- Context window and prompt ordering
- Decoding, temperature, and randomness
- Live notebook experiments using the Gemini API

---

### 4. Module 2: Retrieval-Augmented Generation (RAG)
- Why LLMs need external knowledge
- How retrieval improves reliability
- High-level view of search + generation systems

---

### 5. Module 3: Hugging Face & Agentic AI
- Using open-source models
- What agentic AI means in practice
- LLMs combined with tools and workflows

---

### 6. Final Hands-On Project
- Modify provided templates to build an AI feature
- Apply prompts, retrieval, or agents
- Focus on system design, not perfection

---

## Key Takeaway

LLMs are **probabilistic models conditioned on context**.  
Modern AI systems are built by **controlling inputs, context, and decoding**, not by retraining models.

---

## Prerequisites
- Basic Python familiarity
- Gemini API key (instructions provided during the session)

---

## Tools Used
- Google Gemini API
- Python & Jupyter Notebooks
- Hugging Face ecosystem (conceptual)

---
